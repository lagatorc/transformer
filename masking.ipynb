{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_dot_product_attention(Q, K, V, mask):\n",
    "    \"\"\"\n",
    "    Calculates the dot product attention weights\n",
    "    and returns a matrix Z, which is the same size as \n",
    "    Q, K, and V.\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    Q - The result of applying Wq to X. \n",
    "      - Shape (..., sequence_len, dim_Wq)\n",
    "    K - The result of applying Wk to X. \n",
    "      - Shape (..., sequence_len, dim_Wk)\n",
    "    V - The result of applying Wv to X. \n",
    "      - Shape (..., sequence_len, dim_Wv)\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    Z - The matrix created by applying the scaled attention \n",
    "            weights to the V matrix.\n",
    "      - Shape (..., sequence_len, model_dim)\n",
    "      \n",
    "    \"\"\"\n",
    "    #Normalizing Q\n",
    "    Q = tf.divide(Q, tf.norm(Q, axis=-1, keepdims=True))\n",
    "    \n",
    "    #Normalizing K\n",
    "    K = tf.divide(K, tf.norm(K, axis=-1, keepdims=True))\n",
    "    \n",
    "    #compute the dot product of all query and key vectors (b/c they are normalized 0 >= values <=1\n",
    "    attention_logits = tf.matmul(Q, K, transpose_b=True)\n",
    "    \n",
    "    attention_logits *= 1e2\n",
    "        \n",
    "    if mask is not None:\n",
    "        attention_logits += (mask * -1e9)\n",
    "    #apply softmax to find the weights\n",
    "    attention_weights = tf.nn.softmax(attention_logits, axis=-1)\n",
    "    #multiply the weights by the Value matrix\n",
    "    Z = tf.matmul(attention_weights, V)\n",
    "    \n",
    "    return Z, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MHAttention(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, num_heads, embedding_dim):\n",
    "        super(MHAttention, self).__init__()\n",
    "        assert embedding_dim % num_heads == 0\n",
    "\n",
    "        self.head_dim = embedding_dim // num_heads\n",
    "        self.num_heads = num_heads\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        self.Wq = tf.keras.layers.Dense(self.embedding_dim)\n",
    "        self.Wk = tf.keras.layers.Dense(self.embedding_dim)\n",
    "        self.Wv = tf.keras.layers.Dense(self.embedding_dim)\n",
    "\n",
    "        self.Wz = tf.keras.layers.Dense(self.embedding_dim)\n",
    "        \n",
    "    def create_heads(self, x, batch_size):\n",
    "        \n",
    "        return tf.reshape(tf.transpose(x), (batch_size, self.num_heads, -1, self.head_dim))\n",
    "        \n",
    "    def call(self, q, k, v, mask):\n",
    "         \n",
    "        batch_size = q.shape[0]\n",
    "        \n",
    "        q = self.Wq(q)\n",
    "        k = self.Wk(k)\n",
    "        v = self.Wv(v)\n",
    "        \n",
    "        q = self.create_heads(q, batch_size)\n",
    "        k = self.create_heads(k, batch_size)\n",
    "        v = self.create_heads(v, batch_size)\n",
    "        \n",
    "        z, attention_weights = normalized_dot_product_attention(q, k, v, mask)\n",
    "        \n",
    "        concat_z = tf.transpose(z, perm=[0, 2, 1, 3])\n",
    "        \n",
    "        concat_z = tf.reshape(concat_z, (batch_size, -1, self.embedding_dim))\n",
    "        \n",
    "        z = self.Wz(concat_z)\n",
    "        \n",
    "        return z, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by \n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[1., 1., 2., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = tf.constant([[1, 1, 2, 0, 0]], dtype=tf.float32)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5, 8), dtype=float32, numpy=\n",
       "array([[[ 0.04474348,  0.00889816,  0.03163097,  0.01507231,\n",
       "         -0.01323302, -0.01447612,  0.01418469, -0.01816808],\n",
       "        [ 0.04474348,  0.00889816,  0.03163097,  0.01507231,\n",
       "         -0.01323302, -0.01447612,  0.01418469, -0.01816808],\n",
       "        [ 0.04628273, -0.02669678,  0.03306064,  0.01664596,\n",
       "         -0.03828354,  0.02165109,  0.00331752, -0.04323517],\n",
       "        [-0.00194035, -0.03082768, -0.01232624, -0.01268417,\n",
       "         -0.00213158, -0.0156741 , -0.00873809,  0.00684651],\n",
       "        [-0.00194035, -0.03082768, -0.01232624, -0.01268417,\n",
       "         -0.00213158, -0.0156741 , -0.00873809,  0.00684651]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = tf.keras.layers.Embedding(3, 8)\n",
    "y_embedded = embed(y)\n",
    "y_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 1, 1, 5), dtype=float32, numpy=array([[[[0., 0., 0., 1., 1.]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=\n",
       " array([[[[0., 1., 1., 1., 1.],\n",
       "          [0., 0., 1., 1., 1.],\n",
       "          [0., 0., 0., 1., 1.],\n",
       "          [0., 0., 0., 1., 1.],\n",
       "          [0., 0., 0., 1., 1.]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1, 1, 5), dtype=float32, numpy=array([[[[0., 0., 0., 1., 1.]]]], dtype=float32)>)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(y, y)\n",
    "create_masks(y, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "mha = MHAttention(1, 8)\n",
    "out, attn_weights = mha(y_embedded, y_embedded, y_embedded, enc_padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.0000000e+00, 2.6526348e-19, 1.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "        [1.6504135e-38, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "        [5.8382332e-28, 1.0000000e+00, 5.0394636e-12, 0.0000000e+00,\n",
       "         0.0000000e+00]]], dtype=float32)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
